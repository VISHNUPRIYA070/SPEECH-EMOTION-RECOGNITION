# SPEECH-EMOTION-RECOGNITION
PYTHON (jupter)
This project focuses on speech emotion recognition using machine learning . Initially, the dataset is preprocessed by extracting audio features such as MFCCs while applying data augmentation techniques like noise addition, time stretching, shifting, and pitch modification to enhance model robustness. The extracted features are stored in a structured format and one-hot encoded for multi-class classification. Three models are trained and evaluated: K- Nearest Neighbors (KNN), Support Vector Machine (SVM), and Random Forest (RF), with RF achieving the best performance. A trained Random Forest model is then used for real- time emotion prediction from new audio samples, classifying emotions into angry, drunk, painful, and stressful categories. The trained model is saved using Joblib for future use, allowing predictions on unseen audio files. Finally, real-time testing is performed by extracting features from a new audio file, predicting its emotion, and playing the file for verification. The project demonstrates an end-to-end workflow for emotion recognition from speech, highlighting the importance of feature engineering, data augmentation, and model selection in achieving high accuracy.
